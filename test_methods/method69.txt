[[[private void processSamples() throws Exception {
    int ret;
    int sample_format = samples_frame.format();
    int planes = av_sample_fmt_is_planar(sample_format) != 0 ? (int) samples_frame.channels() : 1;
    int data_size = av_samples_get_buffer_size((IntPointer) null, audio_c.channels(), samples_frame.nb_samples(), audio_c.sample_fmt(), 1) / planes;
    if (samples_buf == null || samples_buf.length != planes) {
        samples_ptr = new BytePointer[planes];
        samples_buf = new Buffer[planes];
    }
    frame.sampleRate = audio_c.sample_rate();
    frame.audioChannels = audio_c.channels();
    frame.samples = samples_buf;
    frame.opaque = samples_frame;
    int sample_size = data_size / av_get_bytes_per_sample(sample_format);
    for (int i = 0; i < planes; i++) {
        BytePointer p = samples_frame.data(i);
        if (!p.equals(samples_ptr[i]) || samples_ptr[i].capacity() < data_size) {
            samples_ptr[i] = p.capacity(data_size);
            ByteBuffer b = p.asBuffer();
            switch(sample_format) {
                case AV_SAMPLE_FMT_U8:
                case AV_SAMPLE_FMT_U8P:
                    samples_buf[i] = b;
                    break;
                case AV_SAMPLE_FMT_S16:
                case AV_SAMPLE_FMT_S16P:
                    samples_buf[i] = b.asShortBuffer();
                    break;
                case AV_SAMPLE_FMT_S32:
                case AV_SAMPLE_FMT_S32P:
                    samples_buf[i] = b.asIntBuffer();
                    break;
                case AV_SAMPLE_FMT_FLT:
                case AV_SAMPLE_FMT_FLTP:
                    samples_buf[i] = b.asFloatBuffer();
                    break;
                case AV_SAMPLE_FMT_DBL:
                case AV_SAMPLE_FMT_DBLP:
                    samples_buf[i] = b.asDoubleBuffer();
                    break;
                default:
                    assert false;
            }
        }
        samples_buf[i].position(0).limit(sample_size);
    }
    if (audio_c.channels() != getAudioChannels() || audio_c.sample_fmt() != getSampleFormat() || audio_c.sample_rate() != getSampleRate()) {
        if (samples_convert_ctx == null || samples_channels != getAudioChannels() || samples_format != getSampleFormat() || samples_rate != getSampleRate()) {
            samples_convert_ctx = swr_alloc_set_opts(samples_convert_ctx, av_get_default_channel_layout(getAudioChannels()), getSampleFormat(), getSampleRate(), av_get_default_channel_layout(audio_c.channels()), audio_c.sample_fmt(), audio_c.sample_rate(), 0, null);
            if (samples_convert_ctx == null) {
                throw new Exception("swr_alloc_set_opts() error: Cannot allocate the conversion context.");
            } else if ((ret = swr_init(samples_convert_ctx)) < 0) {
                throw new Exception("swr_init() error " + ret + ": Cannot initialize the conversion context.");
            }
            samples_channels = getAudioChannels();
            samples_format = getSampleFormat();
            samples_rate = getSampleRate();
        }
        int sample_size_in = samples_frame.nb_samples();
        int planes_out = av_sample_fmt_is_planar(samples_format) != 0 ? (int) samples_frame.channels() : 1;
        int sample_size_out = swr_get_out_samples(samples_convert_ctx, sample_size_in);
        int sample_bytes_out = av_get_bytes_per_sample(samples_format);
        int buffer_size_out = sample_size_out * sample_bytes_out * (planes_out > 1 ? 1 : samples_channels);
        if (samples_buf_out == null || samples_buf.length != planes_out || samples_ptr_out[0].capacity() < buffer_size_out) {
            for (int i = 0; samples_ptr_out != null && i < samples_ptr_out.length; i++) {
                av_free(samples_ptr_out[i].position(0));
            }
            samples_ptr_out = new BytePointer[planes_out];
            samples_buf_out = new Buffer[planes_out];
            for (int i = 0; i < planes_out; i++) {
                samples_ptr_out[i] = new BytePointer(av_malloc(buffer_size_out)).capacity(buffer_size_out);
                ByteBuffer b = samples_ptr_out[i].asBuffer();
                switch(samples_format) {
                    case AV_SAMPLE_FMT_U8:
                    case AV_SAMPLE_FMT_U8P:
                        samples_buf_out[i] = b;
                        break;
                    case AV_SAMPLE_FMT_S16:
                    case AV_SAMPLE_FMT_S16P:
                        samples_buf_out[i] = b.asShortBuffer();
                        break;
                    case AV_SAMPLE_FMT_S32:
                    case AV_SAMPLE_FMT_S32P:
                        samples_buf_out[i] = b.asIntBuffer();
                        break;
                    case AV_SAMPLE_FMT_FLT:
                    case AV_SAMPLE_FMT_FLTP:
                        samples_buf_out[i] = b.asFloatBuffer();
                        break;
                    case AV_SAMPLE_FMT_DBL:
                    case AV_SAMPLE_FMT_DBLP:
                        samples_buf_out[i] = b.asDoubleBuffer();
                        break;
                    default:
                        assert false;
                }
            }
        }
        frame.sampleRate = samples_rate;
        frame.audioChannels = samples_channels;
        frame.samples = samples_buf_out;
        if ((ret = swr_convert(samples_convert_ctx, plane_ptr.put(samples_ptr_out), sample_size_out, plane_ptr2.put(samples_ptr), sample_size_in)) < 0) {
            throw new Exception("swr_convert() error " + ret + ": Cannot convert audio samples.");
        }
        for (int i = 0; i < planes_out; i++) {
            samples_ptr_out[i].position(0).limit(ret * (planes_out > 1 ? 1 : samples_channels));
            samples_buf_out[i].position(0).limit(ret * (planes_out > 1 ? 1 : samples_channels));
        }
    }
}]]],